新版爬虫：
	使用urllib2代替urllib库
	下载网页时，先压缩再下载，减少网络通信量
	
实验结果：
	约15分钟，与之前的25分钟相比有较大提升




-----------------------------------------------------------------------------
ps：学校网络访问不了http://www.22mm.cc，在程序中设置使用本地goagent代理，proxies={'http':'http://127.0.0.1:8087'}

	在启动程序默认不使用本地goagent代理，当指定参数选项：-p True时，使用本地goagent代理

爬虫主体思想：
	
	1.默认使用http://www.22mm.cc作为种子地址，放入队列url_queue，http://www.22mm.cc的MD5值放入集合url_set（队列url_queue用于存储url，包含页面链接url和图片地址url，做深度遍历；url_set用于判断页面地址url是否已经遍历）
	
	2.判断url_queue是否为空或者下载的图片数量是否满足设置要求，若满足条件，则进入步骤6；否则进入步骤3
	
	3.在url_queue取出一个url，若是页面链接地址，则进入步骤4；若是图片地址则进入步骤5
	
	4.判断页面链接地址url的md5是否在url_set，若在，则进入步骤2，进入下一次循环；若不在，则把新的url的md5值放入url_set，使用正则表达式提取该页面的链接url和图片地址url，放入队列url_queue，则进入步骤2，进入下一次循环
	
	5.url是图片地址，若url的md5不在pic_url_set中，生成url的md5放入pic_url_set，然后下载图片，生成图片的md5，判断是否在pic_set中，若不在，则把md5放入pic_set，并保存图片，则进入步骤2，进入下一次循环；若在，则进入步骤2，进入下一次循环；若url的md5在pic_url_set中，则进入步骤2，进入下一次循环
	
	6.程序终止


需要注意的地方：
	
	1.多线程访问数据，要注意数据是否是线程安全
		
		Python中队列是线程安全的，因此可以多线程直接访问
		
		Python中集合不是线程安全的，因此在程序中创建了三个锁变量，分别作用于url_set、pic_url_set和pic_set（全局的图片下载数量的变量在pic_set的临界区更新）的访问临界区，确保数据一致性
	
	2.图片唯一性
		
		使用图片md5值判断，而非图片地址md5值判断（防止相同图片存储在不同的地址中）
		这样判断的代价，需要下载图片，浪费网络带宽，效率低
		3.图片写入文件问题
		
		当较大图片写入文件时，可能出现异常，下载的图片可能是损坏的，需要做异常处理，重新下载出现异常的图片


问题：
	
	1. 不要把非相关的图片也爬了；
		
		分析页面代码，<img src="图片地址.jpg">都是以绝对地址存在，使用正则可以简单的过滤出来
	
	2. 你总该考虑多线程吧？或者协程；
		
		用类包装的多线程
	
	3. 命令行-h可以查看程序运行帮助，-n可以指定并发线程数（默认10个），-o可以指定图片存储在哪个目录（默认当前运行目录的pics目录下），-l可以限制爬多少图片就结束（默认不限制）；
		
		用OptionParser()对象
	
	4. 思考个问题，如果下次我要爬其他的美女网站，你这个程序如何尽可能利于复用；
		
		使用更多参数定义程序的行为，而非硬编码（如指定种子地址、http代理等）
		
		对处理步骤进一步细化，降低耦合性，并且每一步，考虑尽可能多的情况（如由js产生的图片地址等）
		
		对付反爬虫(如大网站一般会限定ip、流量等)
		
		程序异常处理，使程序稳定运行（如不规则参数等）
	
	5. 把你的实现思路清晰记录在该爬虫项目的目录下：readme.txt；
		
		如上主体思想
	
	6. 你可以用Python内置模块与第三方模块来加速你这个任务；
		
		暂时没有思路
	
	7. 两周内搞定；
		
		搞定


测试环境：
	
	系统:	win7
	
	IDE：	eclipse pydev
	
	python:	2.7
	
	内存：	2G
	
	网络：	寝室电脑使用vpn（实验室架设的vpn服务器，免费上网~~）上网，在程序中硬编程了使用本地goagent代理访问网站（proxies={'http':'http://127.0.0.1:8087'}，校园网不能访问该网站，因此使用代理）
	

测试结果（默认参数）：
	
	执行命令：python mm_spider.py -p True
	
	运行时间：约25分钟
	
	下载图片：5793张
